#!/usr/bin/env python3
"""
Static malware analysis script.
Extracts hashes, PE metadata, strings, imports, entropy, and suspicious indicators.
"""

import argparse
import hashlib
import math
import re
import struct
import sys
from collections import Counter
from datetime import datetime, timezone
from pathlib import Path


def calculate_hashes(data: bytes) -> dict:
    """Calculate MD5, SHA1, SHA256, and imphash placeholder."""
    return {
        "md5": hashlib.md5(data).hexdigest(),
        "sha1": hashlib.sha1(data).hexdigest(),
        "sha256": hashlib.sha256(data).hexdigest(),
    }


def calculate_entropy(data: bytes) -> float:
    """Calculate Shannon entropy of data."""
    if not data:
        return 0.0
    counter = Counter(data)
    length = len(data)
    entropy = -sum((count / length) * math.log2(count / length) for count in counter.values())
    return round(entropy, 4)


def extract_strings(data: bytes, min_length: int = 4) -> dict:
    """Extract ASCII and Unicode strings."""
    ascii_pattern = rb'[\x20-\x7e]{%d,}' % min_length
    unicode_pattern = rb'(?:[\x20-\x7e]\x00){%d,}' % min_length
    
    ascii_strings = [s.decode('ascii', errors='ignore') for s in re.findall(ascii_pattern, data)]
    unicode_strings = [s.decode('utf-16-le', errors='ignore') for s in re.findall(unicode_pattern, data)]
    
    return {
        "ascii": ascii_strings,
        "unicode": unicode_strings,
        "total_count": len(ascii_strings) + len(unicode_strings)
    }


def find_suspicious_strings(strings: list) -> dict:
    """Identify strings that indicate malicious behavior."""
    patterns = {
        "urls": r'https?://[^\s<>"{}|\\^`\[\]]+',
        "ips": r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b',
        "emails": r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
        "registry_keys": r'(?:HKEY_|HKLM|HKCU|HKCR)[\\a-zA-Z0-9_]+',
        "file_paths": r'[A-Za-z]:\\[^\s<>"|?*]+',
        "crypto_wallets": {
            "btc": r'\b[13][a-km-zA-HJ-NP-Z1-9]{25,34}\b',
            "eth": r'\b0x[a-fA-F0-9]{40}\b',
        }
    }
    
    suspicious_apis = [
        "VirtualAlloc", "VirtualProtect", "WriteProcessMemory", "CreateRemoteThread",
        "NtUnmapViewOfSection", "SetWindowsHookEx", "GetAsyncKeyState", "RegSetValueEx",
        "InternetOpen", "URLDownloadToFile", "WinExec", "ShellExecute", "CreateProcess",
        "LoadLibrary", "GetProcAddress", "IsDebuggerPresent", "CheckRemoteDebuggerPresent",
        "CryptEncrypt", "CryptDecrypt", "CryptAcquireContext", "BCryptEncrypt",
        "socket", "connect", "send", "recv", "WSAStartup", "gethostbyname",
    ]
    
    all_strings = " ".join(strings)
    results = {}
    
    for name, pattern in patterns.items():
        if isinstance(pattern, dict):
            results[name] = {}
            for subname, subpattern in pattern.items():
                matches = list(set(re.findall(subpattern, all_strings)))
                if matches:
                    results[name][subname] = matches
        else:
            matches = list(set(re.findall(pattern, all_strings)))
            if matches:
                results[name] = matches
    
    found_apis = [api for api in suspicious_apis if api.lower() in all_strings.lower()]
    if found_apis:
        results["suspicious_apis"] = found_apis
    
    return results


def parse_pe_header(data: bytes) -> dict | None:
    """Parse PE header for metadata."""
    if len(data) < 64:
        return None
    
    # Check MZ signature
    if data[:2] != b'MZ':
        return None
    
    try:
        pe_offset = struct.unpack('<I', data[0x3C:0x40])[0]
        
        if len(data) < pe_offset + 4 or data[pe_offset:pe_offset+4] != b'PE\x00\x00':
            return None
        
        # COFF header
        machine = struct.unpack('<H', data[pe_offset+4:pe_offset+6])[0]
        num_sections = struct.unpack('<H', data[pe_offset+6:pe_offset+8])[0]
        timestamp = struct.unpack('<I', data[pe_offset+8:pe_offset+12])[0]
        characteristics = struct.unpack('<H', data[pe_offset+22:pe_offset+24])[0]
        
        # Optional header
        optional_offset = pe_offset + 24
        magic = struct.unpack('<H', data[optional_offset:optional_offset+2])[0]
        
        is_64bit = magic == 0x20b
        arch = "x64" if is_64bit else "x86"
        
        machine_types = {
            0x14c: "i386",
            0x8664: "AMD64",
            0x1c0: "ARM",
            0xaa64: "ARM64",
        }
        
        compile_time = datetime.fromtimestamp(timestamp, tz=timezone.utc).isoformat() if timestamp else "Unknown"
        
        # Parse sections
        optional_header_size = struct.unpack('<H', data[pe_offset+20:pe_offset+22])[0]
        section_offset = pe_offset + 24 + optional_header_size
        
        sections = []
        for i in range(min(num_sections, 20)):  # Limit to 20 sections
            sec_start = section_offset + (i * 40)
            if sec_start + 40 > len(data):
                break
            
            name = data[sec_start:sec_start+8].rstrip(b'\x00').decode('ascii', errors='ignore')
            virtual_size = struct.unpack('<I', data[sec_start+8:sec_start+12])[0]
            raw_size = struct.unpack('<I', data[sec_start+16:sec_start+20])[0]
            raw_offset = struct.unpack('<I', data[sec_start+20:sec_start+24])[0]
            sec_chars = struct.unpack('<I', data[sec_start+36:sec_start+40])[0]
            
            # Calculate section entropy
            if raw_offset + raw_size <= len(data):
                sec_data = data[raw_offset:raw_offset+raw_size]
                sec_entropy = calculate_entropy(sec_data)
            else:
                sec_entropy = 0.0
            
            sections.append({
                "name": name,
                "virtual_size": virtual_size,
                "raw_size": raw_size,
                "entropy": sec_entropy,
                "executable": bool(sec_chars & 0x20000000),
                "writable": bool(sec_chars & 0x80000000),
            })
        
        # Detect packing indicators
        packing_indicators = []
        for sec in sections:
            if sec["entropy"] > 7.0:
                packing_indicators.append(f"High entropy in {sec['name']}: {sec['entropy']}")
            if sec["name"] in ["UPX0", "UPX1", ".packed", ".aspack", ".adata"]:
                packing_indicators.append(f"Known packer section: {sec['name']}")
        
        # Check for suspicious section characteristics
        for sec in sections:
            if sec["executable"] and sec["writable"]:
                packing_indicators.append(f"RWX section: {sec['name']}")
        
        return {
            "type": "PE32+" if is_64bit else "PE32",
            "architecture": arch,
            "machine": machine_types.get(machine, f"Unknown (0x{machine:x})"),
            "compile_timestamp": compile_time,
            "timestamp_raw": timestamp,
            "num_sections": num_sections,
            "sections": sections,
            "is_dll": bool(characteristics & 0x2000),
            "is_executable": bool(characteristics & 0x0002),
            "packing_indicators": packing_indicators,
        }
        
    except (struct.error, ValueError, IndexError) as e:
        return {"error": str(e)}


def detect_file_type(data: bytes) -> str:
    """Detect file type based on magic bytes."""
    signatures = {
        b'MZ': "PE Executable (Windows)",
        b'\x7fELF': "ELF Executable (Linux)",
        b'\xfe\xed\xfa\xce': "Mach-O (macOS, 32-bit)",
        b'\xfe\xed\xfa\xcf': "Mach-O (macOS, 64-bit)",
        b'\xca\xfe\xba\xbe': "Mach-O Universal Binary",
        b'PK\x03\x04': "ZIP Archive (possibly DOCX/XLSX/JAR)",
        b'Rar!\x1a\x07': "RAR Archive",
        b'\x1f\x8b': "GZIP",
        b'%PDF': "PDF Document",
        b'\xd0\xcf\x11\xe0': "OLE Compound (DOC/XLS/PPT)",
        b'{\rt': "RTF Document",
    }
    
    for sig, filetype in signatures.items():
        if data.startswith(sig):
            return filetype
    
    # Check for scripts
    first_line = data[:100].split(b'\n')[0]
    if b'#!/' in first_line:
        if b'python' in first_line.lower():
            return "Python Script"
        elif b'bash' in first_line or b'/sh' in first_line:
            return "Shell Script"
        elif b'perl' in first_line:
            return "Perl Script"
    
    if data[:50].strip().startswith((b'<script', b'<html', b'<!DOCTYPE')):
        return "HTML/JavaScript"
    
    return "Unknown"


def analyze_file(filepath: str, output_format: str = "text") -> dict:
    """Perform complete static analysis on a file."""
    path = Path(filepath)
    
    if not path.exists():
        return {"error": f"File not found: {filepath}"}
    
    data = path.read_bytes()
    
    # Basic info
    hashes = calculate_hashes(data)
    file_type = detect_file_type(data)
    overall_entropy = calculate_entropy(data)
    
    # Strings
    strings = extract_strings(data)
    all_strings = strings["ascii"] + strings["unicode"]
    suspicious = find_suspicious_strings(all_strings)
    
    # PE analysis if applicable
    pe_info = None
    if file_type.startswith("PE"):
        pe_info = parse_pe_header(data)
    
    results = {
        "file": {
            "name": path.name,
            "size": len(data),
            "type": file_type,
        },
        "hashes": hashes,
        "entropy": {
            "overall": overall_entropy,
            "assessment": "Likely packed/encrypted" if overall_entropy > 7.0 else "Normal" if overall_entropy < 6.5 else "Potentially compressed",
        },
        "strings": {
            "total": strings["total_count"],
            "ascii_count": len(strings["ascii"]),
            "unicode_count": len(strings["unicode"]),
        },
        "suspicious_indicators": suspicious,
    }
    
    if pe_info:
        results["pe_analysis"] = pe_info
    
    return results


def format_output(results: dict, format_type: str = "text") -> str:
    """Format analysis results for output."""
    if format_type == "json":
        import json
        return json.dumps(results, indent=2, default=str)
    
    # Text format
    lines = []
    lines.append("=" * 70)
    lines.append("STATIC MALWARE ANALYSIS REPORT")
    lines.append("=" * 70)
    
    # File info
    f = results["file"]
    lines.append(f"\n[FILE INFORMATION]")
    lines.append(f"  Filename:    {f['name']}")
    lines.append(f"  Size:        {f['size']:,} bytes")
    lines.append(f"  Type:        {f['type']}")
    
    # Hashes
    h = results["hashes"]
    lines.append(f"\n[CRYPTOGRAPHIC HASHES]")
    lines.append(f"  MD5:         {h['md5']}")
    lines.append(f"  SHA1:        {h['sha1']}")
    lines.append(f"  SHA256:      {h['sha256']}")
    
    # Entropy
    e = results["entropy"]
    lines.append(f"\n[ENTROPY ANALYSIS]")
    lines.append(f"  Overall:     {e['overall']}")
    lines.append(f"  Assessment:  {e['assessment']}")
    
    # PE Analysis
    if "pe_analysis" in results and results["pe_analysis"]:
        pe = results["pe_analysis"]
        if "error" not in pe:
            lines.append(f"\n[PE HEADER ANALYSIS]")
            lines.append(f"  Format:      {pe['type']}")
            lines.append(f"  Architecture: {pe['architecture']} ({pe['machine']})")
            lines.append(f"  Compile Time: {pe['compile_timestamp']}")
            lines.append(f"  DLL:         {'Yes' if pe['is_dll'] else 'No'}")
            lines.append(f"  Sections:    {pe['num_sections']}")
            
            if pe.get("sections"):
                lines.append(f"\n  [SECTIONS]")
                for sec in pe["sections"]:
                    flags = []
                    if sec["executable"]: flags.append("X")
                    if sec["writable"]: flags.append("W")
                    flag_str = ",".join(flags) if flags else "-"
                    lines.append(f"    {sec['name']:<10} Size: {sec['raw_size']:<10} Entropy: {sec['entropy']:<6} Flags: {flag_str}")
            
            if pe.get("packing_indicators"):
                lines.append(f"\n  [PACKING INDICATORS]")
                for indicator in pe["packing_indicators"]:
                    lines.append(f"    âš  {indicator}")
    
    # Strings summary
    s = results["strings"]
    lines.append(f"\n[STRINGS ANALYSIS]")
    lines.append(f"  Total:       {s['total']}")
    lines.append(f"  ASCII:       {s['ascii_count']}")
    lines.append(f"  Unicode:     {s['unicode_count']}")
    
    # Suspicious indicators
    si = results["suspicious_indicators"]
    if si:
        lines.append(f"\n[SUSPICIOUS INDICATORS]")
        
        if si.get("urls"):
            lines.append(f"  URLs ({len(si['urls'])}):")
            for url in si["urls"][:10]:
                lines.append(f"    - {url}")
            if len(si["urls"]) > 10:
                lines.append(f"    ... and {len(si['urls']) - 10} more")
        
        if si.get("ips"):
            lines.append(f"  IP Addresses ({len(si['ips'])}):")
            for ip in si["ips"][:10]:
                lines.append(f"    - {ip}")
        
        if si.get("registry_keys"):
            lines.append(f"  Registry Keys ({len(si['registry_keys'])}):")
            for key in si["registry_keys"][:5]:
                lines.append(f"    - {key}")
        
        if si.get("file_paths"):
            lines.append(f"  File Paths ({len(si['file_paths'])}):")
            for path in si["file_paths"][:5]:
                lines.append(f"    - {path}")
        
        if si.get("suspicious_apis"):
            lines.append(f"  Suspicious APIs ({len(si['suspicious_apis'])}):")
            for api in sorted(si["suspicious_apis"]):
                lines.append(f"    - {api}")
        
        if si.get("crypto_wallets"):
            for wallet_type, addresses in si["crypto_wallets"].items():
                lines.append(f"  {wallet_type.upper()} Wallets ({len(addresses)}):")
                for addr in addresses[:3]:
                    lines.append(f"    - {addr}")
    
    lines.append("\n" + "=" * 70)
    
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="Static malware analysis tool")
    parser.add_argument("file", help="Path to file to analyze")
    parser.add_argument("-f", "--format", choices=["text", "json"], default="text", help="Output format")
    parser.add_argument("-o", "--output", help="Output file (default: stdout)")
    
    args = parser.parse_args()
    
    results = analyze_file(args.file, args.format)
    output = format_output(results, args.format)
    
    if args.output:
        Path(args.output).write_text(output)
        print(f"Results written to {args.output}")
    else:
        print(output)


if __name__ == "__main__":
    main()
